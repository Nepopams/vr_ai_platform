# =============================================================================
# AI Platform â€” Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# NEVER commit .env with real secrets!
# =============================================================================

# -----------------------------------------------------------------------------
# LLM Core (llm_policy/)
# -----------------------------------------------------------------------------
# Master switch for LLM policy. Set to "true" to enable LLM features.
LLM_POLICY_ENABLED=false

# API key for the LLM provider. REQUIRED when LLM_POLICY_ENABLED=true.
LLM_API_KEY=your-api-key-here

# Base URL for the LLM API (e.g. https://api.openai.com/v1).
LLM_BASE_URL=

# Policy routing profile ("cheap", "quality", etc.).
LLM_POLICY_PROFILE=cheap

# Path to custom policy YAML file. Leave empty for built-in policy.
LLM_POLICY_PATH=

# Allow placeholder responses instead of real LLM calls (dev/test only).
# Must be "false" for bootstrap to register a real caller.
LLM_POLICY_ALLOW_PLACEHOLDERS=false

# -----------------------------------------------------------------------------
# Agent Runner (agent_runner/)
# -----------------------------------------------------------------------------
# LLM provider name ("openai", "yandex").
LLM_PROVIDER=openai

# Model identifier.
LLM_MODEL=gpt-4o-mini

# LLM temperature (0.0 = deterministic, 1.0 = creative).
LLM_TEMPERATURE=0.1

# Request timeout in milliseconds (takes precedence over OPENAI_TIMEOUT_S).
# LLM_TIMEOUT_MS=

# Fallback timeout in seconds (used if LLM_TIMEOUT_MS is not set).
# OPENAI_TIMEOUT_S=15

# Maximum output tokens. Leave unset for provider default.
# LLM_MAX_OUTPUT_TOKENS=

# Whether to store completions on the provider side.
LLM_STORE=false

# Project identifier for the LLM provider.
LLM_PROJECT=

# Agent runner server host and port.
LLM_AGENT_RUNNER_HOST=0.0.0.0
LLM_AGENT_RUNNER_PORT=8089

# Agent runner URL for client connections.
LLM_AGENT_RUNNER_URL=

# -----------------------------------------------------------------------------
# Shadow Router (routers/shadow_config.py)
# -----------------------------------------------------------------------------
# Enable shadow LLM router (parallel LLM calls, no impact on decisions).
SHADOW_ROUTER_ENABLED=false

# Timeout for shadow router LLM calls (ms).
SHADOW_ROUTER_TIMEOUT_MS=150

# Shadow router log file path.
SHADOW_ROUTER_LOG_PATH=logs/shadow_router.jsonl

# Shadow router mode.
SHADOW_ROUTER_MODE=shadow

# -----------------------------------------------------------------------------
# Assist Mode (routers/assist/)
# -----------------------------------------------------------------------------
# Master switch for assist mode.
ASSIST_MODE_ENABLED=false

# Individual assist features (all require ASSIST_MODE_ENABLED=true).
ASSIST_NORMALIZATION_ENABLED=false
ASSIST_ENTITY_EXTRACTION_ENABLED=false
ASSIST_CLARIFY_ENABLED=false

# Timeout for assist LLM calls (ms).
ASSIST_TIMEOUT_MS=200

# Assist log file path.
ASSIST_LOG_PATH=logs/assist.jsonl

# -----------------------------------------------------------------------------
# Assist Agent Hints (routers/assist/)
# -----------------------------------------------------------------------------
# Enable agent-backed entity extraction hints.
ASSIST_AGENT_HINTS_ENABLED=false

# Agent ID for hints (from agent registry).
ASSIST_AGENT_HINTS_AGENT_ID=

# Capability to request from agent.
ASSIST_AGENT_HINTS_CAPABILITY=extract_entities.shopping

# Comma-separated allowlist of intents for agent hints.
ASSIST_AGENT_HINTS_ALLOWLIST=

# Sampling rate for agent hints (0.0 = off, 1.0 = all).
ASSIST_AGENT_HINTS_SAMPLE_RATE=0.0

# Timeout for agent hint calls (ms).
ASSIST_AGENT_HINTS_TIMEOUT_MS=120

# -----------------------------------------------------------------------------
# Partial Trust (routers/partial_trust_config.py)
# -----------------------------------------------------------------------------
# Enable partial trust corridor (LLM decisions accepted for allowed intents).
PARTIAL_TRUST_ENABLED=false

# Intent allowed for partial trust. Only "add_shopping_item" is supported.
PARTIAL_TRUST_INTENT=add_shopping_item

# Sampling rate for partial trust (0.0-1.0).
PARTIAL_TRUST_SAMPLE_RATE=0.01

# Timeout for partial trust LLM calls (ms).
PARTIAL_TRUST_TIMEOUT_MS=200

# Profile ID for partial trust (optional).
PARTIAL_TRUST_PROFILE_ID=

# Risk log file path for partial trust decisions.
PARTIAL_TRUST_RISK_LOG_PATH=logs/partial_trust_risk.jsonl

# -----------------------------------------------------------------------------
# Shadow Agent (routers/shadow_agent_config.py)
# -----------------------------------------------------------------------------
# Enable shadow agent invoker (parallel agent calls for comparison).
SHADOW_AGENT_INVOKER_ENABLED=false

# Path to agent registry YAML.
SHADOW_AGENT_REGISTRY_PATH=agent_registry/agent-registry-v0.yaml

# Comma-separated allowlist of agent IDs.
SHADOW_AGENT_ALLOWLIST=

# Sampling rate for shadow agent invocations (0.0-1.0).
SHADOW_AGENT_SAMPLE_RATE=0.0

# Timeout for shadow agent calls (ms).
SHADOW_AGENT_TIMEOUT_MS=150

# Enable diff logging for shadow agent results.
SHADOW_AGENT_DIFF_LOG_ENABLED=false

# Diff log file path.
SHADOW_AGENT_DIFF_LOG_PATH=logs/shadow_agent_diff.jsonl

# -----------------------------------------------------------------------------
# Agent Registry (agent_registry/)
# -----------------------------------------------------------------------------
# Enable agent registry.
AGENT_REGISTRY_ENABLED=false

# Path to agent registry YAML (overrides default).
# AGENT_REGISTRY_PATH=

# Enable agent registry integration in core pipeline.
AGENT_REGISTRY_CORE_ENABLED=false

# -----------------------------------------------------------------------------
# Shopping Extractor Client (app/llm/agent_runner_client.py)
# -----------------------------------------------------------------------------
# Enable LLM-based shopping extractor.
LLM_SHOPPING_EXTRACTOR_ENABLED=false

# Shopping extractor mode ("shadow" or "active").
LLM_SHOPPING_EXTRACTOR_MODE=shadow

# Timeout for shopping extractor calls (seconds).
LLM_SHOPPING_EXTRACTOR_TIMEOUT_S=5

# -----------------------------------------------------------------------------
# Pipeline Logging
# -----------------------------------------------------------------------------
# Pipeline latency instrumentation.
PIPELINE_LATENCY_LOG_ENABLED=true
PIPELINE_LATENCY_LOG_PATH=logs/pipeline_latency.jsonl

# Fallback metrics logging.
FALLBACK_METRICS_LOG_ENABLED=true
FALLBACK_METRICS_LOG_PATH=logs/fallback_metrics.jsonl

# Decision log paths.
DECISION_LOG_PATH=logs/decisions.jsonl
DECISION_TEXT_LOG_PATH=logs/decision_text.jsonl

# PRIVACY WARNING: Logs raw user text when enabled. Use only for debugging.
LOG_USER_TEXT=false

# Agent run log.
AGENT_RUN_LOG_ENABLED=false
AGENT_RUN_LOG_PATH=logs/agent_run.jsonl

# -----------------------------------------------------------------------------
# Routing
# -----------------------------------------------------------------------------
# Decision router strategy version.
DECISION_ROUTER_STRATEGY=v1
